{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EL2O.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VMBoehm/DeNoPa/blob/master/EL2O.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "D-Fe5G8m1FTC",
        "colab_type": "code",
        "outputId": "b9ced403-90b9-476c-90f3-28433102dce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "%pylab inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-AEYmOsH1FTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "9d24f18b-a245-42c6-eace-d7f6e14785f3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.python.ops.parallel_for.gradients import jacobian\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "# IMAGE_SHAPE = [28, 28, 1]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8KfB25JnmYDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDsbrs3BmYqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Simple recovery of a multivariate Gaussian by taking gradients at samples; this is **EL2O** 'by hand'"
      ]
    },
    {
      "metadata": {
        "id": "FxZ3yhvU1FTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "batch_size  = 2#256\n",
        "hidden_size = 4\n",
        "\n",
        "\n",
        "sample_size = tf.placeholder_with_default(500,shape=[])\n",
        "\n",
        "\n",
        "ini_val = np.ones((batch_size,(hidden_size *(hidden_size +1)) // 2),dtype=np.float32)\n",
        "mu_t    = tf.constant(np.zeros((batch_size,hidden_size), dtype=np.float32))\n",
        "                   \n",
        "sigma_t = tf.constant(ini_val)\n",
        "\n",
        "sigma_t2 = tfd.matrix_diag_transform(tfd.fill_triangular(sigma_t), transform=tf.nn.softplus)\n",
        "\n",
        "\n",
        "approx_posterior2 = tfd.MultivariateNormalTriL(loc=mu_t,scale_tril=sigma_t2, name='posterior2')\n",
        "\n",
        "z2                = approx_posterior2.sample()\n",
        "\n",
        "big_sample        = approx_posterior2.sample(sample_size)\n",
        "\n",
        "xx                = tf.Variable(z2)\n",
        "\n",
        "p_of_z            = -approx_posterior2.log_prob(xx)\n",
        "\n",
        "dpdz              = tf.gradients(p_of_z, xx) \n",
        "\n",
        "dpdz              = tf.gather(dpdz, 0)\n",
        "\n",
        "hess              = tf.hessians(p_of_z,xx)\n",
        "\n",
        "hess              = tf.gather(hess, 0)\n",
        "\n",
        "hess2             = tf.reduce_sum( hess, axis = 2 )\n",
        "\n",
        "eigen             = tf.linalg.eigh(hess2)\n",
        "\n",
        "sigma_new         = tf.linalg.inv(hess2)\n",
        "#sigma_new         = (sigma_new+tf.linalg.transpose(sigma_new))/2.\n",
        "\n",
        "eigen2            = tf.linalg.eigh(sigma_new)\n",
        "\n",
        "mu_new            = -tf.einsum('ijk,ik->ij', sigma_new,dpdz)+xx\n",
        "\n",
        "sigma_ch          = tf.linalg.cholesky(sigma_new)\n",
        "\n",
        "approx_posterior3 = tfd.MultivariateNormalFullCovariance(loc=mu_new, covariance_matrix=sigma_new)\n",
        "\n",
        "\n",
        "z3                = approx_posterior3.sample(sample_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxr2SDLG-VFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "check if we recover correct mean and covariances:"
      ]
    },
    {
      "metadata": {
        "id": "2RuGuvHKYowk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "549ff96c-57b1-4125-9770-7b6ce2480ca1"
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "#covariances agree\n",
        "res, res2= sess.run([sigma_t2, sigma_ch])\n",
        "print(res,res2)\n",
        "\n",
        "#means agree\n",
        "mu, mu_n= sess.run([mu_t,mu_new])\n",
        "print(mu,mu_n)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1.3132616 0.        0.        0.       ]\n",
            "  [1.        1.3132616 0.        0.       ]\n",
            "  [1.        1.        1.3132616 0.       ]\n",
            "  [1.        1.        1.        1.3132616]]\n",
            "\n",
            " [[1.3132616 0.        0.        0.       ]\n",
            "  [1.        1.3132616 0.        0.       ]\n",
            "  [1.        1.        1.3132616 0.       ]\n",
            "  [1.        1.        1.        1.3132616]]] [[[1.3132615  0.         0.         0.        ]\n",
            "  [1.         1.3132614  0.         0.        ]\n",
            "  [0.9999999  0.99999964 1.3132616  0.        ]\n",
            "  [0.9999999  0.99999964 0.9999999  1.3132617 ]]\n",
            "\n",
            " [[1.3132615  0.         0.         0.        ]\n",
            "  [1.         1.3132614  0.         0.        ]\n",
            "  [0.9999999  0.99999964 1.3132616  0.        ]\n",
            "  [0.9999999  0.99999964 0.9999999  1.3132617 ]]]\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]] [[-2.3841858e-07  8.3446503e-07  4.7683716e-07  2.3841858e-07]\n",
            " [ 2.3841858e-07 -1.7881393e-07 -9.5367432e-07 -4.7683716e-07]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WsYUd49i-aSe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "and plot samples from the distributions"
      ]
    },
    {
      "metadata": {
        "id": "SWApsFOMk_D9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "fa6e0e92-1ee4-48c0-8f24-e19f382d12e9"
      },
      "cell_type": "code",
      "source": [
        "res, res2= sess.run([big_sample,z3])\n",
        "plt.hist(res.flatten(),bins=50)\n",
        "plt.hist(res2.flatten(),alpha=0.5,bins=50)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  2.,   6.,   5.,   4.,   6.,   8.,   7.,  22.,  23.,  27.,  30.,\n",
              "         39.,  58.,  67.,  75., 107., 113., 131., 138., 153., 197., 194.,\n",
              "        208., 210., 249., 227., 206., 205., 180., 171., 152., 160., 101.,\n",
              "        107.,  98.,  46.,  59.,  47.,  36.,  41.,  18.,  12.,  12.,   7.,\n",
              "         13.,  10.,   8.,   2.,   1.,   2.]),\n",
              " array([-5.96197891, -5.7198505 , -5.47772209, -5.23559368, -4.99346527,\n",
              "        -4.75133686, -4.50920845, -4.26708004, -4.02495163, -3.78282322,\n",
              "        -3.54069481, -3.2985664 , -3.05643799, -2.81430958, -2.57218117,\n",
              "        -2.33005276, -2.08792435, -1.84579594, -1.60366753, -1.36153912,\n",
              "        -1.11941071, -0.8772823 , -0.63515388, -0.39302547, -0.15089706,\n",
              "         0.09123135,  0.33335976,  0.57548817,  0.81761658,  1.05974499,\n",
              "         1.3018734 ,  1.54400181,  1.78613022,  2.02825863,  2.27038704,\n",
              "         2.51251545,  2.75464386,  2.99677227,  3.23890068,  3.48102909,\n",
              "         3.7231575 ,  3.96528591,  4.20741432,  4.44954273,  4.69167114,\n",
              "         4.93379955,  5.17592796,  5.41805637,  5.66018478,  5.90231319,\n",
              "         6.1444416 ]),\n",
              " <a list of 50 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Cgu5CPmLtHXI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "now let's see if we can automize this by minimizing the **EL2O**"
      ]
    },
    {
      "metadata": {
        "id": "6Cl2Mv-2tGgB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "batch_size  = 2\n",
        "hidden_size = 4\n",
        "\n",
        "lr          = tf.placeholder_with_default(0.001,shape=[])\n",
        "sample_size = tf.placeholder_with_default(500,shape=[])\n",
        "\n",
        "\n",
        "# this is the true distribution\n",
        "ini_val = np.ones((batch_size,(hidden_size *(hidden_size +1)) // 2),dtype=np.float32)\n",
        "mu_true    = tf.constant(np.zeros((batch_size,hidden_size), dtype=np.float32))                  \n",
        "sigma_true = tf.constant(ini_val)\n",
        "sigma_t2 = tfd.matrix_diag_transform(tfd.fill_triangular(sigma_true), transform=tf.nn.softplus)\n",
        "\n",
        "true_posterior = tfd.MultivariateNormalTriL(loc=mu_true,scale_tril=sigma_t2, name='trueposterior')\n",
        "\n",
        "\n",
        "# this is going to be our approximation of the posterior\n",
        "ini_val      = 1.2*np.ones((batch_size,(hidden_size *(hidden_size +1)) // 2),dtype=np.float32)\n",
        "mu_approx    = tf.Variable(initial_value=0.5*np.ones((batch_size,hidden_size), dtype=np.float32))                  \n",
        "sigma_approx = tf.Variable(ini_val)\n",
        "sigma_approx2= tfd.matrix_diag_transform(tfd.fill_triangular(sigma_approx), transform=tf.nn.softplus)\n",
        "\n",
        "approx_posterior = tfd.MultivariateNormalTriL(loc=mu_approx,scale_tril=sigma_approx2, name='approxposterior')\n",
        "\n",
        "z                = approx_posterior.sample()\n",
        "\n",
        "xx               = tf.Variable(z)\n",
        "\n",
        "p_of_z           = -approx_posterior.log_prob(xx)\n",
        "pt_of_z          = -true_posterior.log_prob(xx)\n",
        "\n",
        "dpdz              = tf.gradients(p_of_z, xx) \n",
        "\n",
        "dpdz              = tf.gather(dpdz, 0)\n",
        "\n",
        "dptdz             = tf.gradients(pt_of_z, xx) \n",
        "\n",
        "dptdz             = tf.gather(dptdz, 0)\n",
        "\n",
        "hess              = tf.hessians(p_of_z,xx)\n",
        "\n",
        "hess              = tf.gather(hess, 0)\n",
        "\n",
        "hess2             = tf.reduce_sum( hess, axis = 2 )\n",
        "\n",
        "#sets values that are double to zero\n",
        "lowt              = tf.matrix_band_part(hess2, -1, 0)\n",
        "\n",
        "hesst             = tf.hessians(pt_of_z,xx)\n",
        "\n",
        "hesst             = tf.gather(hesst, 0)\n",
        "\n",
        "hesst2            = tf.reduce_sum( hesst, axis = 2 )\n",
        "\n",
        "lowt2             = tf.matrix_band_part(hesst2, -1, 0)\n",
        "\n",
        "EL2O              = tf.reduce_sum(tf.math.square(dpdz-dptdz))+tf.reduce_sum(tf.math.square((lowt-lowt2)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "48Bg6IO_4LbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "opt_op    = optimizer.minimize(EL2O,var_list=[mu_approx,sigma_approx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQd6zTBey2yn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYZzJkPE5YcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f01982a-f084-4fe8-b1e3-29b9482f2976"
      },
      "cell_type": "code",
      "source": [
        "lrate= 0.05\n",
        "for ii in range(2000):\n",
        "  _, loss  = sess.run([opt_op, EL2O], feed_dict={lr:lrate})\n",
        "print(loss)"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.9867085e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AWRsFRwW-kGh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "this seems to work, too, but at some additional cost, could probably optimize the optimization with second derivatives..."
      ]
    },
    {
      "metadata": {
        "id": "OiMEUXAF5afq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "ae8c3c11-465e-4523-d505-129f05bf2e1f"
      },
      "cell_type": "code",
      "source": [
        "### seems to be working too!\n",
        "res, res2, mut, sigmat = sess.run([mu_approx,sigma_approx2,mu_true,sigma_t2])\n",
        "print(res,mut)\n",
        "print(res2,sigmat)"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00743369 0.01199255 0.01502631 0.01653728]\n",
            " [0.08273391 0.1304898  0.1697108  0.18788718]] [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "[[[1.3111266  0.         0.         0.        ]\n",
            "  [0.9946116  1.3116595  0.         0.        ]\n",
            "  [0.99309546 0.99669147 1.3126882  0.        ]\n",
            "  [0.992199   0.9959294  0.99890435 1.3131263 ]]\n",
            "\n",
            " [[1.3308675  0.         0.         0.        ]\n",
            "  [1.0444174  1.3248684  0.         0.        ]\n",
            "  [1.0615145  1.029821   1.3208656  0.        ]\n",
            "  [1.070637   1.0374932  1.0152241  1.3151367 ]]] [[[1.3132616 0.        0.        0.       ]\n",
            "  [1.        1.3132616 0.        0.       ]\n",
            "  [1.        1.        1.3132616 0.       ]\n",
            "  [1.        1.        1.        1.3132616]]\n",
            "\n",
            " [[1.3132616 0.        0.        0.       ]\n",
            "  [1.        1.3132616 0.        0.       ]\n",
            "  [1.        1.        1.3132616 0.       ]\n",
            "  [1.        1.        1.        1.3132616]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNqpfz1GnBTB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "start with a Laplace approximation"
      ]
    },
    {
      "metadata": {
        "id": "5mN6eUiSe1b9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "batch_size  = 2\n",
        "hidden_size = 4\n",
        "\n",
        "lr          = tf.placeholder_with_default(0.001,shape=[])\n",
        "sample_size = tf.placeholder_with_default(500,shape=[])\n",
        "\n",
        "\n",
        "# this is the true distribution\n",
        "ini_val = np.ones((batch_size,(hidden_size *(hidden_size +1)) // 2),dtype=np.float32)\n",
        "mu_true    = tf.constant(np.zeros((batch_size,hidden_size), dtype=np.float32))                  \n",
        "sigma_true = tf.constant(ini_val)\n",
        "sigma_t2 = tfd.matrix_diag_transform(tfd.fill_triangular(sigma_true), transform=tf.nn.softplus)\n",
        "\n",
        "true_posterior = tfd.MultivariateNormalTriL(loc=mu_true,scale_tril=sigma_t2, name='trueposterior')\n",
        "\n",
        "\n",
        "# this is going to be our approximation of the posterior\n",
        "\n",
        "mu_approx    = tf.Variable(initial_value=0.5*np.ones((batch_size,hidden_size), dtype=np.float32))       \n",
        "\n",
        "# get hessian at mean of approximate posterior\n",
        "x_           = tf.Variable(mu_approx)\n",
        "p_mu         = -true_posterior.log_prob(x_)\n",
        "\n",
        "hessl        = tf.hessians(p_mu,x_)\n",
        "\n",
        "hessl        = tf.gather(hessl, 0)\n",
        "\n",
        "hessl        = tf.reduce_sum(hessl, axis = 2 )\n",
        "\n",
        "sigmal       = tf.linalg.inv(hessl)\n",
        "\n",
        "chol         = tf.linalg.cholesky(sigmal)\n",
        "\n",
        "\n",
        "tf.stop_gradient(sigma_approx)\n",
        "# and use the derived sigma as initial sigma -> Laplace approximation\n",
        "sigma_approx = tf.Variable(chol)\n",
        "\n",
        "approx_posterior = tfd.MultivariateNormalTriL(loc=mu_approx,scale_tril=sigma_approx, name='approxposterior')\n",
        "\n",
        "z                = approx_posterior.sample()\n",
        "\n",
        "xx               = tf.Variable(z)\n",
        "\n",
        "p_of_z           = -approx_posterior.log_prob(xx)\n",
        "pt_of_z          = -true_posterior.log_prob(xx)\n",
        "\n",
        "dpdz              = tf.gradients(p_of_z, xx) \n",
        "\n",
        "dpdz              = tf.gather(dpdz, 0)\n",
        "\n",
        "dptdz             = tf.gradients(pt_of_z, xx) \n",
        "\n",
        "dptdz             = tf.gather(dptdz, 0)\n",
        "\n",
        "hess              = tf.hessians(p_of_z,xx)\n",
        "\n",
        "hess              = tf.gather(hess, 0)\n",
        "\n",
        "hess2             = tf.reduce_sum( hess, axis = 2 )\n",
        "\n",
        "#sets values that are double to zero\n",
        "lowt              = tf.matrix_band_part(hess2, -1, 0)\n",
        "\n",
        "hesst             = tf.hessians(pt_of_z,xx)\n",
        "\n",
        "hesst             = tf.gather(hesst, 0)\n",
        "\n",
        "hesst2            = tf.reduce_sum( hesst, axis = 2 )\n",
        "\n",
        "lowt2             = tf.matrix_band_part(hesst2, -1, 0)\n",
        "\n",
        "EL2O              = tf.reduce_sum(tf.math.square(dpdz-dptdz))+tf.reduce_sum(tf.math.square((lowt-lowt2)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXrRA2IzBRL9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "opt_op    = optimizer.minimize(EL2O,var_list=[mu_approx,sigma_approx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c31EZuXgBpnV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_suraE2DlOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d87db413-0232-4249-8b29-e9ef82a5d9ac"
      },
      "cell_type": "code",
      "source": [
        "#starting at laplace in this case, gives lower EL2O\n",
        "lrate= 0.05\n",
        "for ii in range(2000):\n",
        "  _, loss  = sess.run([opt_op, EL2O], feed_dict={lr:lrate})\n",
        "print(loss)"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.412061e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BVM0cf6WDn2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "2761ad55-0810-4d8c-fcba-cb002ef10fb5"
      },
      "cell_type": "code",
      "source": [
        "### seems to be working too!\n",
        "res, res2, mut, sigmat = sess.run([mu_approx,sigma_approx,mu_true,sigma_t2])\n",
        "print(res,mut)\n",
        "print(res2,sigmat)"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00913437 0.01422298 0.01857121 0.02040558]\n",
            " [0.00597881 0.009539   0.01204131 0.01334246]] [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "[[[1.3110282  0.         0.         0.        ]\n",
            "  [0.99377674 1.3112942  0.         0.        ]\n",
            "  [0.9918645  0.99556506 1.3124146  0.        ]\n",
            "  [0.99038756 0.99523526 0.99783605 1.3132738 ]]\n",
            "\n",
            " [[1.3117437  0.         0.         0.        ]\n",
            "  [0.9963134  1.3122506  0.         0.        ]\n",
            "  [0.9949883  0.9976562  1.3127372  0.        ]\n",
            "  [0.9943018  0.99709946 0.9989153  1.3131356 ]]] [[[1.3132616 0.        0.        0.       ]\n",
            "  [1.        1.3132616 0.        0.       ]\n",
            "  [1.        1.        1.3132616 0.       ]\n",
            "  [1.        1.        1.        1.3132616]]\n",
            "\n",
            " [[1.3132616 0.        0.        0.       ]\n",
            "  [1.        1.3132616 0.        0.       ]\n",
            "  [1.        1.        1.3132616 0.       ]\n",
            "  [1.        1.        1.        1.3132616]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yqr2zZeGDs6D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6rGR8CvD3iZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}